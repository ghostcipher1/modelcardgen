{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAR Demo: End-to-End Model Card Generation\n",
    "\n",
    "This notebook demonstrates the complete workflow:\n",
    "1. Train a simple classifier\n",
    "2. Compute evaluation metrics\n",
    "3. Generate a model card\n",
    "4. Generate a risk report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from modelcardgen.core.trainer import ClassifierTrainer\n",
    "from modelcardgen.core.models import (\n",
    "    ModelMetadata,\n",
    "    DatasetMetadata,\n",
    "    ModelLimitations,\n",
    "    UseCaseConstraints,\n",
    "    RiskAssessment,\n",
    ")\n",
    "from modelcardgen.reports.markdown import MarkdownCardGenerator\n",
    "from modelcardgen.reports.risk import RiskReportGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Sample Data\n",
    "\n",
    "Create a synthetic binary classification dataset for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train and Evaluate Classifier\n",
    "\n",
    "Use the ClassifierTrainer to train a Random Forest and compute metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=10)\n",
    "\n",
    "trainer = ClassifierTrainer(model, test_size=0.2, random_state=42)\n",
    "metrics = trainer.train_and_evaluate(X, y)\n",
    "\n",
    "print(f\"Accuracy: {metrics.accuracy:.3f}\")\n",
    "print(f\"Precision: {metrics.precision:.3f}\")\n",
    "print(f\"Recall: {metrics.recall:.3f}\")\n",
    "print(f\"F1-Score: {metrics.f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Model Metadata and Documentation\n",
    "\n",
    "Create descriptive metadata about the model, datasets, limitations, and use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = ModelMetadata(\n",
    "    name=\"Binary Classification Model\",\n",
    "    version=\"1.0.0\",\n",
    "    description=\"A Random Forest classifier for binary classification tasks. Trained on synthetic data to demonstrate the CLEAR reporting framework.\",\n",
    "    owner=\"Data Science Team\",\n",
    "    license=\"Apache-2.0\",\n",
    "    framework=\"scikit-learn\"\n",
    ")\n",
    "\n",
    "training_data = DatasetMetadata(\n",
    "    name=\"Synthetic Training Set\",\n",
    "    description=\"Synthetically generated binary classification dataset with 20 features and balanced classes.\",\n",
    "    size=800,\n",
    "    features=[f\"feature_{i}\" for i in range(20)],\n",
    "    target=\"binary_label\"\n",
    ")\n",
    "\n",
    "eval_data = DatasetMetadata(\n",
    "    name=\"Synthetic Test Set\",\n",
    "    description=\"Holdout test set from the same distribution as training data.\",\n",
    "    size=200,\n",
    "    features=[f\"feature_{i}\" for i in range(20)],\n",
    "    target=\"binary_label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limitations = ModelLimitations(\n",
    "    unsuitable_inputs=[\n",
    "        \"Missing or null feature values\",\n",
    "        \"Features outside the training range\",\n",
    "        \"Non-numeric input types\"\n",
    "    ],\n",
    "    environmental_constraints=\"Requires Python 3.10+ and scikit-learn>=1.0. Inference latency: <10ms per sample.\",\n",
    "    out_of_scope_uses=[\n",
    "        \"Real-time decision systems without human review\",\n",
    "        \"Safety-critical applications (medical, aviation)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "constraints = UseCaseConstraints(\n",
    "    intended_users=[\n",
    "        \"Data scientists evaluating model performance\",\n",
    "        \"ML engineers deploying the model\",\n",
    "        \"Stakeholders reviewing model capabilities\"\n",
    "    ],\n",
    "    intended_use_cases=[\n",
    "        \"Demonstrating CLEAR reporting framework\",\n",
    "        \"Educational examples\",\n",
    "        \"Model card generation workflows\"\n",
    "    ],\n",
    "    prohibited_uses=[\n",
    "        \"Production deployment without additional validation\",\n",
    "        \"Use with real-world data without retraining\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Risk Assessments\n",
    "\n",
    "Identify and document potential risks associated with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = [\n",
    "    RiskAssessment(\n",
    "        risk_type=\"Dataset Shift\",\n",
    "        description=\"Model was trained on synthetic data with balanced classes. Real-world data may have different distributions.\",\n",
    "        mitigation_strategy=\"Monitor prediction distributions in production. Retrain quarterly with new data.\",\n",
    "        severity=\"Medium\"\n",
    "    ),\n",
    "    RiskAssessment(\n",
    "        risk_type=\"Limited Generalization\",\n",
    "        description=\"Only 20 features used. May not capture domain-specific relationships important for decision-making.\",\n",
    "        mitigation_strategy=\"Conduct feature importance analysis. Engage domain experts to validate feature selection.\",\n",
    "        severity=\"Medium\"\n",
    "    ),\n",
    "    RiskAssessment(\n",
    "        risk_type=\"No Uncertainty Quantification\",\n",
    "        description=\"Model provides binary predictions without confidence scores or uncertainty estimates.\",\n",
    "        mitigation_strategy=\"Implement prediction confidence thresholding. Flag low-confidence predictions for human review.\",\n",
    "        severity=\"Low\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Model Card\n",
    "\n",
    "Create a comprehensive model card in Markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_generator = MarkdownCardGenerator()\n",
    "\n",
    "card_path = card_generator.generate(\n",
    "    metadata=metadata,\n",
    "    training_data=training_data,\n",
    "    eval_data=eval_data,\n",
    "    metrics=metrics,\n",
    "    limitations=limitations,\n",
    "    constraints=constraints,\n",
    "    risks=risks,\n",
    "    output_path=\"DEMO_MODEL_CARD.md\"\n",
    ")\n",
    "\n",
    "print(f\"Model card generated: {card_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate Risk Report\n",
    "\n",
    "Create a detailed risk assessment report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_generator = RiskReportGenerator()\n",
    "\n",
    "risk_path = risk_generator.generate(\n",
    "    model_name=\"Binary Classification Model\",\n",
    "    model_version=\"1.0.0\",\n",
    "    risks=risks,\n",
    "    metrics=metrics,\n",
    "    output_path=\"DEMO_RISK_REPORT.md\"\n",
    ")\n",
    "\n",
    "print(f\"Risk report generated: {risk_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Preview Generated Files\n",
    "\n",
    "Display the first section of each generated report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DEMO_MODEL_CARD.md\", \"r\") as f:\n",
    "    model_card_content = f.read()\n",
    "\n",
    "print(\"=== MODEL CARD (First 500 characters) ===\")\n",
    "print(model_card_content[:500])\n",
    "print(\"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DEMO_RISK_REPORT.md\", \"r\") as f:\n",
    "    risk_report_content = f.read()\n",
    "\n",
    "print(\"=== RISK REPORT (First 500 characters) ===\")\n",
    "print(risk_report_content[:500])\n",
    "print(\"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete CLEAR workflow:\n",
    "\n",
    "1. **Trained a classifier** using the ClassifierTrainer wrapper\n",
    "2. **Computed evaluation metrics** automatically from sklearn outputs\n",
    "3. **Defined model metadata** and documented intended use, limitations, and risks\n",
    "4. **Generated a model card** in Markdown format\n",
    "5. **Generated a risk report** for governance and compliance\n",
    "\n",
    "All the heavy lifting happens in the package modules. The notebook stays focused on the workflow, not implementation details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
